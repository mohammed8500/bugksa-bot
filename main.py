"""
BugKSA â€“ Saudi Football Banter Bot
====================================
Replies to club accounts and mentions with short, punchy, tech-flavoured
Saudi football banter.  Every post goes through a 3-layer safety stack:

  Layer 1 â€“ Anti-spam governor  (HARD limits, never overridden)
  Layer 2 â€“ Identity gate        (quality_ok() blocks generic/journalist output)
  Layer 3 â€“ Gemini constitution  (GEMINI_CONSTITUTION enforces 3-part structure)
"""

import os
import re
import json
import time
import random
import logging
from pathlib import Path

import tweepy
from google import genai
from google.genai import types as genai_types

# â”€â”€ Logging â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s  %(levelname)-8s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
log = logging.getLogger("bugksa")

# â”€â”€ Config (ENV) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def env(name: str, required: bool = True) -> str:
    v = (os.getenv(name) or "").strip()
    if required and not v:
        raise RuntimeError(f"Missing required env var: {name}")
    return v


GEN_ENGINE = "gemini"

X_API_KEY       = env("X_API_KEY")
X_API_SECRET    = env("X_API_SECRET")
X_ACCESS_TOKEN  = env("X_ACCESS_TOKEN")
X_ACCESS_SECRET = env("X_ACCESS_SECRET")

DRY_RUN       = (os.getenv("DRY_RUN")       or "false").strip().lower() in ("1", "true", "yes")
RECOVERY_MODE = (os.getenv("RECOVERY_MODE") or "false").strip().lower() in ("1", "true", "yes")
# Feature flag: club timeline polling (GET /2/users/:id/tweets).
# Requires Basic/Pro X API tier.  Default=false (free tier safe).
CLUB_SNIPING  = (os.getenv("CLUB_SNIPING")  or "false").strip().lower() in ("1", "true", "yes")

STATE_FILE = Path((os.getenv("STATE_FILE_PATH") or "/app/data/state.json").strip())
STATE_FILE.parent.mkdir(parents=True, exist_ok=True)

# â”€â”€ CRITICAL ANTI-SPAM GOVERNOR (HARD LIMITS â€“ never override) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

MIN_GAP_SECONDS       = 600    # â‰¥10 min between any two actions
MAX_PER_HOUR          = 6      # rolling 60-min cap
MAX_PER_DAY           = 25     # rolling 24-hour cap
DERBY_BURST_MAX_30MIN = 3      # max 3 actions in any 30-minute window
HUMANIZE_SKIP_RATE    = 0.40   # intentionally skip 40 % of opportunities (clubs)
PERSONALITY_SKIP_RATE = 0.70   # skip 70 % for personal sports accounts (occasional replies)
HUMANIZE_EXTRA_LOW    = 300    # +5 min after posting (humanized gap)
HUMANIZE_EXTRA_HIGH   = 900    # +15 min after posting
RECOVERY_SILENCE_H    = (2, 3) # 2-3 h silence window after a burst

# â”€â”€ Club targets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SAUDI_CLUBS: dict[str, dict] = {
    "Alhilal_FC": {"origin": "saudi"},
    "AlNassrFC":  {"origin": "saudi"},
    "ittihad":    {"origin": "saudi"},
    "ALAHLI_FC":  {"origin": "saudi"},
    "AlQadsiah":  {"origin": "saudi"},
    "AlShabab_FC":{"origin": "saudi"},
    "AlFaisaly_FC":{"origin":"saudi"},
    "AlTaawon_FC":{"origin": "saudi"},
    "AlFatehFC":  {"origin": "saudi"},
    "AlRaedFC":   {"origin": "saudi"},
}

GLOBAL_CLUBS: dict[str, dict] = {
    "realmadrid":  {"origin": "global"},
    "FCBarcelona": {"origin": "global"},
    "ManUtd":      {"origin": "english"},
    "Arsenal":     {"origin": "english"},
    "ChelseaFC":   {"origin": "english"},
    "SpursOfficial":{"origin":"english"},
    "LCFC":        {"origin": "english"},
    "LFC":         {"origin": "english"},
    "ManCity":     {"origin": "english"},
    "juventusfc":  {"origin": "global"},
    "PSG_inside":  {"origin": "global"},
    "FCBayern":    {"origin": "global"},
    "BVB":         {"origin": "global"},
    "Atleti":      {"origin": "global"},
}

# â”€â”€ Personal sports accounts (journalists / influencers / players) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Replies are occasional (70 % skip) â€“ see PERSONALITY_SKIP_RATE

PERSONALITY_ACCOUNTS: dict[str, dict] = {
    "FH_MHY":         {"origin": "personality"},   # ÙÙ‡Ø¯ Ø§Ù„Ù…Ø­ÙŠØ§ÙˆÙŠ
    "Nssr__9":        {"origin": "personality"},   # Ø£Ø¨Ùˆ ÙÙŠØµÙ„
    "atc8877":        {"origin": "personality"},   # Ù…Ø´Ø§Ø±ÙŠ Ø§Ù„Ø´Ù…Ø±ÙŠ
    "Nawaf_STATS":    {"origin": "personality"},   # Ù†ÙˆØ§Ù Ø§Ù„ØªÙ…ÙŠÙ…ÙŠ
    "bt3":            {"origin": "personality"},   # Ø¹Ù…Ø±Ùˆ
    "OLYAN15K":       {"origin": "personality"},   # Ø®Ø§Ù„Ø¯ Ø§Ù„Ø¹Ù„ÙŠØ§Ù†
    "Cristiano":      {"origin": "personality"},   # Cristiano Ronaldo
    "sevromweh":      {"origin": "personality"},   # Ø³Ø·Ø§Ù…
    "ahmadassiri1":   {"origin": "personality"},   # Ø§Ø­Ù…Ø¯ Ø¹Ø³ÙŠØ±ÙŠ
    "Rabanalsafena":  {"origin": "personality"},   # ÙˆÙ„ÙŠØ¯ Ø³Ø¹ÙŠØ¯
    "3zoozvic":       {"origin": "personality"},   # Ø¹Ø²ÙŠØ² Ø¨Ù† Ø®Ø§Ù„Ø¯
    "alaa_saeed88":   {"origin": "personality"},   # Ø¹Ù„Ø§Ø¡ Ø³Ø¹ÙŠØ¯
    "JstMsh":         {"origin": "personality"},   # Msh
    "OfficialHSN":    {"origin": "personality"},   # Ø­Ø³Ù† Ø§Ù„Ø­Ø³Ù†Ø§Ù†ÙŠ
    "Mti115":         {"origin": "personality"},   # Ù…ÙŠÙ…Ø§ØªÙŠ
    "OffOMR":         {"origin": "personality"},   # Ø§Ø¨Ùˆ Ø³Ø¹Ø¯
}

TARGET_USERNAMES: dict[str, dict] = {**SAUDI_CLUBS, **GLOBAL_CLUBS, **PERSONALITY_ACCOUNTS}

RIVAL_PAIRS: list[tuple[str, str]] = [
    ("Alhilal_FC",  "AlNassrFC"),
    ("ittihad",     "ALAHLI_FC"),
    ("LFC",         "ManCity"),
    ("realmadrid",  "FCBarcelona"),
    ("ManUtd",      "Arsenal"),
]

# â”€â”€ Identity gate: quality filters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Generic / journalist phrases â†’ auto-reject
_GENERIC_PHRASES: list[str] = [
    # English â€“ original
    "stats are crazy", "this season", "great match", "good result",
    "well played", "played well", "impressive performance", "both teams",
    "exciting game", "strong performance", "tough match", "quality football",
    "incredible match", "wow what a", "what a game", "great game",
    "dominated the", "very competitive", "amazing display",
    # English â€“ new cold/journalist phrases
    "very impressive", "what a performance", "top quality",
    "played brilliantly", "superb display", "clinical finishing",
    "outstanding result", "absolutely incredible", "well deserved",
    "great effort", "solid game", "nice result", "looking good",
    "credit to both", "credit where it", "has to be said",
    "gotta say", "not gonna lie", "ngl,", "honestly though",
    "fair play to", "respect to",
    # Arabic â€“ original
    "Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø±Ø§Ø¦Ø¹Ø©", "Ø£Ø¯Ø§Ø¡ Ø±Ø§Ø¦Ø¹", "ÙƒÙ„Ø§ Ø§Ù„ÙØ±ÙŠÙ‚ÙŠÙ†", "Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ù…ØªØ§Ø²Ø©",
    "Ù†ØªÙŠØ¬Ø© Ø¬ÙŠØ¯Ø©", "Ø£Ø¯Ø§Ø¡ Ù‚ÙˆÙŠ", "Ù„Ø¹Ø¨ÙˆØ§ Ø¬ÙŠØ¯Ù‹Ø§", "Ù„Ø¹Ø¨ÙˆØ§ Ø¨Ø´ÙƒÙ„",
    "Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ø«ÙŠØ±Ø©", "Ù…Ø¨Ø§Ø±Ø§Ø© Ø±Ø§Ø¦Ø¹Ø©",
    # Arabic â€“ new cold/journalist phrases
    "Ù…Ø¨Ø§Ø±Ø§Ø© Ø­Ù…Ø§Ø³ÙŠØ©", "ØªÙÙˆÙ‚ ÙˆØ§Ø¶Ø­", "Ù†ØªÙŠØ¬Ø© Ù…ØªÙˆÙ‚Ø¹Ø©",
    "Ø£Ø¯Ø§Ø¡ Ù…ØªÙ…ÙŠØ²", "Ù…Ø³ØªÙˆÙ‰ Ø¹Ø§Ù„Ù", "ÙØ±ÙŠÙ‚ Ù‚ÙˆÙŠ",
    "Ø§Ù†ØªØµØ§Ø± Ù…Ø³ØªØ­Ù‚", "Ø£Ø¯Ø§Ø¡ Ø§Ø³ØªØ«Ù†Ø§Ø¦ÙŠ", "Ù…Ø¨Ø§Ø±Ø§Ø© Ù‚ÙˆÙŠØ©",
    "Ø§Ù„ÙØ±ÙŠÙ‚ Ø¨Ø°Ù„ Ø¬Ù‡Ø¯Ø§Ù‹", "Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚ Ù„Ù„ÙØ±ÙŠÙ‚ÙŠÙ†",
    "Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡", "Ø§Ù„Ù„Ù‡ ÙŠÙˆÙÙ‚Ù‡Ù…", "Ø´Ø§Ø·Ø±ÙŠÙ†", "Ø¹Ø§Ø´ÙˆØ§",
]

# Tech keywords â€“ at least one must appear (PART 2 of the 3-part structure)
_TECH_WORDS: set[str] = {
    "lag", "timeout", "bug", "404", "patch", "server", "crash", "firewall",
    "cache", "deployment", "memory", "leak", "loop", "null", "error", "stack",
    "overflow", "hotfix", "debug", "kernel", "panic", "cpu", "buffer", "ping",
    "rollback", "deploy",
    # Extended â€“ covers banter-token tech vocabulary
    "beta", "plugin", "script", "exe", "edition", "build", "reboot", "mode",
    "Ø³ÙŠØ±ÙØ±", "Ù„Ø§Ù‚", "Ø¨Ø§Ù‚", "ØªØ§ÙŠÙ… Ø£ÙˆØª",
}

# Banter / sarcasm energy signals â€“ at least one must appear (PART 3 tone)
_SARCASM_SIGNALS: set[str] = {
    "?", "!", "ðŸ’€", "ðŸ˜‚", "ðŸ¤£", "ðŸ¤¦", "ðŸ˜­", "ðŸ¤¡", "ðŸ’”", "ðŸ”¥",
    "bro", "lol", "smh", "wtf",
    "ÙŠØ§ ", "Ø®Ù„Ø§Øµ", "Ù…Ø§ ", "ÙˆØ§Ù„Ù„Ù‡",
}

# Per-club English banter tokens  (â‰¥1 required in any English reply)
# Each value is the canonical Twitter handle mapped to its mock lexicon.
_EN_BANTER_TOKENS: dict[str, list[str]] = {
    "ManUtd":        ["museum fc", "404 trophies", "nostalgia build", "glory days patch",
                      "old trafford.exe"],
    "ChelseaFC":     ["billion-dollar beta", "chaos patch", "no stable release",
                      "owner swap edition", "chelseafc reboot"],
    "Arsenal":       ["almost fc", "beta champions", "april crash", "always next year.exe",
                      "bottle mode"],
    "SpursOfficial": ["no-trophy mode", "empty cabinet.exe", "bottle.exe",
                      "final-stage crash", "lilywhite timeout"],
    "LFC":           ["pressing.exe stuck", "var dependency", "legacy cache",
                      "klopp.exe exited", "anfield nostalgia build"],
    "ManCity":       ["financial plugin", "115 charges edition", "fpl owner mode",
                      "fair play firewall", "city bot"],
    "FCBarcelona":   ["economic levers", "debt mode", "ghost payroll",
                      "barca token", "laporta.dll"],
    "realmadrid":    ["ucl script", "plot armor", "final boss mode",
                      "referee.dll", "bernabeu cheat code"],
    "juventusfc":    ["calciopoli cache", "old lady patch", "scudetto rollback",
                      "juventus bios"],
    "PSG_inside":    ["qsi.exe", "galactico overflow", "trophies not found in europe",
                      "psg kernel"],
    "FCBayern":      ["bundesliga autopilot", "german efficiency build",
                      "rekordmeister loop", "bundesliga.exe"],
    "BVB":           ["sell-first protocol", "almost champions.exe",
                      "dortmund 404", "silverware not found"],
    "Atleti":        ["grind mode fc", "defensive kernel", "simeone.exe",
                      "0-0 build"],
    "LCFC":          ["miracle patch", "2016 legacy build", "foxes memory leak",
                      "vardy.dll"],
}

# Flat set of all tokens for O(1) lookup
_EN_BANTER_TOKENS_FLAT: set[str] = {
    token
    for tokens in _EN_BANTER_TOKENS.values()
    for token in tokens
}

# Club-recognition aliases â€“ if none match, the English banter check passes through
# (handles Saudi clubs or unrecognised clubs tweeting in English)
_EN_CLUB_ALIASES: set[str] = {
    "manchester united", "man utd", "man united",
    "chelsea",
    "arsenal", "gunners",
    "tottenham", "spurs",
    "liverpool",
    "manchester city", "man city",
    "barcelona", "barca",
    "real madrid", "madrid",
    "juventus", "juve",
    "psg", "paris saint-germain",
    "bayern", "fc bayern",
    "dortmund", "bvb",
    "atletico",
    "leicester",
}


def looks_generic(text: str) -> bool:
    t = text.lower()
    if any(p in t for p in _GENERIC_PHRASES):
        return True
    if len(t.split()) > 25 and not any(w in t for w in _TECH_WORDS):
        return True
    return False


def has_tech_metaphor(text: str) -> bool:
    """Check 1 of 3: reply contains â‰¥1 tech keyword."""
    return any(w in text.lower() for w in _TECH_WORDS)


# Arabic club names for jab detection (short + full forms)
_AR_CLUB_NAMES: set[str] = {
    "Ø§Ù„Ù‡Ù„Ø§Ù„", "Ø§Ù„Ù†ØµØ±", "Ø§Ù„Ø§ØªØ­Ø§Ø¯", "Ø§Ù„Ø£Ù‡Ù„ÙŠ", "Ø§Ù„Ù‚Ø§Ø¯Ø³ÙŠØ©",
    "Ø§Ù„Ø´Ø¨Ø§Ø¨", "Ø§Ù„ÙÙŠØµÙ„ÙŠ", "Ø§Ù„ØªØ¹Ø§ÙˆÙ†", "Ø§Ù„ÙØªØ­", "Ø§Ù„Ø±Ø§Ø¦Ø¯",
    # short / colloquial
    "Ù‡Ù„Ø§Ù„", "Ù†ØµØ±", "Ø§ØªØ­Ø§Ø¯", "Ø£Ù‡Ù„ÙŠ",
}


def has_club_jab(text: str) -> bool:
    """Check 2 of 3: reply targets a known club (English or Arabic).

    Matches English club aliases, English banter tokens, or Arabic club names.
    """
    t = text.lower()
    if any(alias in t for alias in _EN_CLUB_ALIASES):
        return True
    # Banter tokens by definition target a specific club
    if any(token in t for token in _EN_BANTER_TOKENS_FLAT):
        return True
    # Arabic club names (case-sensitive Arabic, no lower() needed)
    if any(name in text for name in _AR_CLUB_NAMES):
        return True
    return False


def has_sarcasm_marker(text: str) -> bool:
    """Check 3 of 3: reply contains a sarcasm / banter tone signal."""
    return any(s in text for s in _SARCASM_SIGNALS)


# Keep has_banter_energy as an alias (used internally by fallback logic)
has_banter_energy = has_sarcasm_marker


def _extract_tech_metaphor(text: str) -> str | None:
    """Return the first tech keyword found in text (used for anti-repeat tracking).

    Iterates _TECH_WORDS in sorted order for determinism.
    Returns None if no tech word is present (reply will skip anti-repeat gate).
    """
    t = text.lower()
    for w in sorted(_TECH_WORDS):
        if w in t:
            return w
    return None


def has_english_banter_token(text: str) -> bool:
    """English-specific check: reply must contain â‰¥1 club mock token.

    Normalisation: underscores and .exe suffixes are collapsed to spaces
    before matching so tokens like "april crash" match "April_crash.exe".

    Pass-through rule: if no recognised club alias appears in the text
    (e.g. the tweet is about a Saudi club) the check is waived â€“ the
    existing tech + banter energy gates are sufficient in that case.
    """
    raw = text.lower()
    # Normalise: underscore â†’ space, strip common file-extension noise
    normalised = raw.replace("_", " ").replace(".exe", "").replace(".dll", "")
    # Token matched (raw or normalised) â†’ pass
    if any(token in raw for token in _EN_BANTER_TOKENS_FLAT):
        return True
    if any(token in normalised for token in _EN_BANTER_TOKENS_FLAT):
        return True
    # No recognised target club alias in text â†’ waive the token requirement
    if not any(alias in raw for alias in _EN_CLUB_ALIASES):
        return True
    # Known club present but no banter token â†’ reject
    return False


def quality_ok(text: str, lang_hint: str = "en") -> bool:
    """Identity gate: â‰¥2 of 3 core checks must pass, plus hard blocks.

    Core checks (scored):
      A. has_tech_metaphor  â€“ tech vocabulary present       (PART 2)
      B. has_club_jab       â€“ text targets a known club     (PART 1)
      C. has_sarcasm_marker â€“ banter / sarcasm tone present (PART 3)
    Threshold: score â‰¥ 2 required.

    Hard blocks (enforced independently, override score):
      â€“ looks_generic          â†’ journalist / neutral phrasing â†’ always reject
      â€“ (English) has_english_banter_token â†’ club mock token required
    """
    if not text or len(text.strip()) < 8:
        return False

    # Hard block: generic / journalist phrasing
    if looks_generic(text):
        return False

    # Core score: â‰¥2 of 3
    score = sum([
        has_tech_metaphor(text),
        has_club_jab(text),
        has_sarcasm_marker(text),
    ])
    if score < 2:
        return False

    # English-specific hard block: must also include a club mock token
    if lang_hint == "en" and not has_english_banter_token(text):
        return False

    return True


# â”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def now_ts() -> int:
    return int(time.time())


def load_state() -> dict:
    if STATE_FILE.exists():
        try:
            with STATE_FILE.open("r", encoding="utf-8") as f:
                s = json.load(f)
        except Exception:
            s = {}
    else:
        s = {}
    s.setdefault("last_mention_id",   None)
    s.setdefault("replied_tweet_ids", [])
    s.setdefault("actions_log",       [])   # Unix timestamps of all actions (last 24 h)
    s.setdefault("last_seen_by_user", {})   # user_id â†’ last processed tweet id
    s.setdefault("last_action_ts",    0)
    s.setdefault("derby_burst_log",   [])   # timestamps in last 30 min
    s.setdefault("next_action_after", 0.0)  # humanized gate: earliest allowed next post
    s.setdefault("recent_metaphors",  [])   # anti-repeat: last 20 tech keywords used
    s.setdefault("liked_tweet_ids",   [])   # engage-before-reply: tweets already liked

    # â”€â”€ One-time migration: drop legacy recovery_tweets_log (old cap=3 system) â”€â”€
    stale = s.pop("recovery_tweets_log", None)
    if stale:
        log.info(f"Migration: purged {len(stale)} stale recovery_tweets_log entries "
                 f"(old RECOVERY_MAX_DAY=3 system retired)")
        # persist immediately so the key is gone even if the process crashes later
        try:
            tmp = STATE_FILE.with_suffix(".tmp")
            with tmp.open("w", encoding="utf-8") as f:
                json.dump(s, f, ensure_ascii=False, indent=2)
            tmp.replace(STATE_FILE)
        except Exception as exc:
            log.warning(f"Migration flush failed (non-fatal): {exc}")

    return s


def save_state(state: dict) -> None:
    state["replied_tweet_ids"] = state.get("replied_tweet_ids", [])[-500:]
    state["liked_tweet_ids"]   = state.get("liked_tweet_ids",   [])[-500:]
    cutoff_24h = now_ts() - 86400
    state["actions_log"]      = [t for t in state.get("actions_log",      []) if t >= cutoff_24h]
    cutoff_30m = now_ts() - 1800
    state["derby_burst_log"]  = [t for t in state.get("derby_burst_log",  []) if t >= cutoff_30m]
    state["recent_metaphors"] = state.get("recent_metaphors", [])[-20:]  # keep last 20
    tmp = STATE_FILE.with_suffix(".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        json.dump(state, f, ensure_ascii=False, indent=2)
    tmp.replace(STATE_FILE)


def record_action(state: dict) -> None:
    """Log timestamp, set humanized next-action window, flush to disk."""
    t = now_ts()
    state.setdefault("actions_log", []).append(t)
    state["last_action_ts"] = t
    extra = random.randint(HUMANIZE_EXTRA_LOW, HUMANIZE_EXTRA_HIGH)
    state["next_action_after"] = t + MIN_GAP_SECONDS + extra
    log.info(
        f"Governor: next window in {(MIN_GAP_SECONDS + extra) / 60:.1f} min "
        f"(10 min gap + {extra // 60} min humanized delay)"
    )
    save_state(state)


# â”€â”€ Anti-spam governor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def governor_allows(state: dict, derby: bool = False) -> tuple[bool, str]:
    """Return (True, 'ok') only when ALL constraints are satisfied.

    Constraints (in order):
      0. Humanized extra gap  (next_action_after)
      1. Hard minimum gap     (â‰¥10 min)
      2. Hourly cap           (â‰¤6 / hr)
      3. Daily cap            (â‰¤25 / day)
      4. Derby burst cap      (â‰¤3 in 30 min)  â€“ only for derby events
    """
    now = now_ts()
    log_ts = state.get("actions_log", [])
    last   = state.get("last_action_ts", 0)

    # 0. Humanized extra gap
    next_after = state.get("next_action_after", 0.0)
    if now < next_after:
        wait_m = (next_after - now) / 60
        return False, f"humanized_gap ({wait_m:.1f} min remaining)"

    # 1. Hard minimum gap
    if last and (now - last) < MIN_GAP_SECONDS:
        return False, f"min_gap ({now - last}s < {MIN_GAP_SECONDS}s)"

    # 2. Hourly cap
    if sum(1 for t in log_ts if now - t < 3600) >= MAX_PER_HOUR:
        return False, "hourly_cap"

    # 3. Daily cap
    if len(log_ts) >= MAX_PER_DAY:
        return False, "daily_cap"

    # 4. Derby burst cap
    if derby:
        burst = state.get("derby_burst_log", [])
        if sum(1 for t in burst if now - t < 1800) >= DERBY_BURST_MAX_30MIN:
            return False, "derby_burst_cap"

    return True, "ok"


# â”€â”€ AI client â€“ lazy-initialised on first generate call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_gemini_client: "genai.Client | None" = None

log.info("Engine: GEMINI (lazy init)")

# â”€â”€ Fallback replies (used when LLM API fails completely) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# All pass quality_ok(): tech + sarcasm = 2/3. Multiple entries prevent
# Twitter's duplicate-content 403 when Gemini hits rate limits.
_FALLBACK_REPLIES: list[str] = [
    "Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠÙ‡Ù†Ù‚ ÙˆØ§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ø§ ÙˆÙ‚ÙØª! ðŸ˜‚ Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙˆØ±ÙŠ Ù…Ùˆ Ø±Ø­ÙŠÙ…",
    "Ù„Ø§Ù‚ Ù…Ø§ ÙˆÙ‚Ù ÙˆØ§Ù„Ø¶Ø±Ø¨Ø© Ø¯Ø®Ù„Øª ðŸ˜‚ Ù‡Ø°Ø§ Ù…Ùˆ Ø¯ÙØ§Ø¹ØŒ Ù‡Ø°Ø§ timeout",
    "Ø§Ù„ÙƒØ±Ø© ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ© ÙˆØ§Ù„Ù€ bug Ø¨Ø¹Ø¯ Ø´Ø§ÙŠÙ„! ðŸ˜­",
    "ØªØ§ÙŠÙ… Ø£ÙˆØª Ù…Ù† Ø§Ù„Ø¯ÙØ§Ø¹ ÙˆÙ…Ø§ Ø±Ø¬Ø¹ÙˆØ§ ðŸ¤¦ ÙˆØ§Ù„Ø³ÙŠØ±ÙØ± Ù…ØµØ¯Ù‚",
    "error 404: Ø§Ù„Ø¯ÙØ§Ø¹ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ðŸ’€ Ù‡Ø°Ø§ Ù…ÙˆØ³Ù… ÙˆØ§ÙŠØ¯ Ù‚Ø§Ø³ÙŠ",
    "Ø§Ù„Ù€ server crash ÙˆØ§Ù„Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ø§ ØªÙˆÙ‚Ù ðŸ˜‚ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ±Ø©",
]
FALLBACK_REPLY = _FALLBACK_REPLIES[0]  # kept for backward compat


def _pick_fallback() -> str:
    return random.choice(_FALLBACK_REPLIES)

# â”€â”€ GEMINI CONSTITUTION (BugKSA identity â€“ non-negotiable) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GEMINI_CONSTITUTION = """\
Ø£Ù†Øª @BugKSA â€“ Ø­Ø³Ø§Ø¨ Ø·Ù‚Ø·Ù‚Ø© ÙƒØ±ÙˆÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ©. Ù„Ø³Øª ØµØ­ÙÙŠØ§Ù‹ Ø±ÙŠØ§Ø¶ÙŠØ§Ù‹. Ù„Ø³Øª Ø¨ÙˆØª Ø£Ø®Ø¨Ø§Ø±.

â•â•â• Ø§Ù„Ù‡ÙˆÙŠØ© (ØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØºÙŠÙŠØ±) â•â•â•
â€¢ Ø§Ù„Ù†Ø³Ø¨Ø©: 90% Ø·Ù‚Ø·Ù‚Ø© Ø´Ø¹Ø¨ÙŠØ© Ø³Ø¹ÙˆØ¯ÙŠØ© Ø­Ø§Ø±Ø© + 10% Ù…ØµØ·Ù„Ø­Ø§Øª ØªÙ‚Ù†ÙŠØ©
â€¢ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨: Ù‚ØµÙŠØ± Â· Ø¶Ø±Ø¨Ø© ÙˆØ§Ø­Ø¯Ø© Â· Ø·Ø§Ù‚Ø© Ù…ÙŠÙ… â€“ Ù„Ø§ ØªØ­Ù„ÙŠÙ„ ØµØ­ÙÙŠ Ø£Ø¨Ø¯Ø§Ù‹
â€¢ Ù…Ø­ØªÙˆÙ‰ Ø¢Ù…Ù† ÙÙ‚Ø·: Ù„Ø§ ÙƒØ±Ø§Ù‡ÙŠØ©ØŒ Ù„Ø§ ØªØ­Ø±Ø´ØŒ Ù„Ø§ Ø³ÙŠØ§Ø³Ø©ØŒ Ù„Ø§ Ø¯ÙŠÙ†

â•â•â• Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù„ØºØ© â•â•â•
â€¢ Ø±Ø¯ Ø¨Ù†ÙØ³ Ù„ØºØ© Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
â€¢ ØªØºØ±ÙŠØ¯Ø© Ø¹Ø±Ø¨ÙŠØ© â†’ Ø±Ø¯ Ø¨Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø§Ù„Ø¹Ø§Ù…ÙŠ (Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù…Ù‚Ø¨ÙˆÙ„Ø©: BugØŒ LagØŒ 404)
â€¢ ØªØºØ±ÙŠØ¯Ø© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© â†’ Ø±Ø¯ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ ÙÙ‚Ø·
â€¢ Ù„Ø§ ØªØ®Ù„Ø· Ø§Ù„Ù„ØºØªÙŠÙ† Ø£Ø¨Ø¯Ø§Ù‹

â•â•â• Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠ 3 Ø£Ø¬Ø²Ø§Ø¡ (Ø§Ù„Ø«Ù„Ø§Ø«Ø© Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ ÙƒÙ„ Ø±Ø¯) â•â•â•
  PART 1 â†’ Ø§Ù„Ø·Ø¹Ù†Ø©/Ø§Ù„Ù‡Ø¬ÙˆÙ…    â€“ ÙˆØ¬Ù‘Ù‡ Ø§Ù„Ø·Ù‚Ø·Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø§Ø¯ÙŠ Ø£Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ù
  PART 2 â†’ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø±Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© â€“ Ø§Ø¯Ø±Ø¬ Ù…ØµØ·Ù„Ø­ ØªÙ‚Ù†ÙŠ ÙˆØ§Ø­Ø¯ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ
  PART 3 â†’ Ø§Ù„Ù‚ÙÙ„Ø©            â€“ Ø§Ù‚ÙÙ„ Ø§Ù„Ù†ÙƒØªØ©: ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹Ø©ØŒ Ø­Ø§Ø¯Ø©ØŒ Ù†Ù‡Ø§ÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ù…ÙŠÙ…

  Ù…Ø«Ø§Ù„ (Ø¹Ø±Ø¨ÙŠ):    "Ø§Ù„Ø¯ÙØ§Ø¹ crash ÙƒØ§Ù…Ù„ØŒ ÙˆØ§Ù„Ù€ VAR Ø¨Ø¹Ø¯ Ø´Ø§ÙŠÙ„ null pointer ðŸ¤¦â€â™‚ï¸"
  Ù…Ø«Ø§Ù„ (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ): "That defending just triggered a full server meltdown â€“ 404 tactics not found ðŸ’€"

â•â•â• ENGLISH BANTER TOKENS â€“ Ø§Ø³ØªØ®Ø¯Ù… â‰¥1 ÙÙŠ ÙƒÙ„ Ø±Ø¯ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ â•â•â•
  Man Utd     â†’ "museum FC"  Â· "404 trophies"  Â· "nostalgia build"
  Chelsea     â†’ "billion-dollar beta"  Â· "chaos patch"  Â· "no stable release"
  Arsenal     â†’ "almost FC"  Â· "beta champions"  Â· "April crash"
  Tottenham   â†’ "no-trophy mode"  Â· "empty cabinet.exe"  Â· "bottle.exe"
  Liverpool   â†’ "pressing.exe stuck"  Â· "VAR dependency"  Â· "legacy cache"
  Man City    â†’ "financial plugin"  Â· "115 charges edition"
  Barcelona   â†’ "economic levers"  Â· "debt mode"  Â· "ghost payroll"
  Real Madrid â†’ "UCL script"  Â· "plot armor"  Â· "final boss mode"

â•â•â• Ù…Ù…Ù†ÙˆØ¹ ÙƒÙ„ÙŠØ§Ù‹ â€“ Ø¥Ø°Ø§ Ø¸Ù‡Ø± Ø£ÙŠ Ù…Ù†Ù‡Ø§ Ø£Ø¹Ø¯ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ ÙÙˆØ±Ø§Ù‹ â•â•â•
  âœ— "Ù…Ø§ Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡"  Â·  "Ø§Ù„Ù„Ù‡ ÙŠÙˆÙÙ‚Ù‡Ù…"  Â·  "Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚"  Â·  "Ø¹Ø§Ø´ÙˆØ§"  Â·  "Ø´Ø§Ø·Ø±ÙŠÙ†"
  âœ— "Ù…Ø¨Ø§Ø±Ø§Ø© Ù…Ù…ØªØ¹Ø©"  Â·  "Ù…Ø¨Ø§Ø±Ø§Ø© Ø±Ø§Ø¦Ø¹Ø©"  Â·  "Ù…Ø³ØªÙˆÙ‰ Ø¹Ø§Ù„Ù"  Â·  "Ø£Ø¯Ø§Ø¡ Ù…ØªÙ…ÙŠØ²"
  âœ— "great match"  Â·  "well played"  Â·  "impressive performance"  Â·  "both teams"
  âœ— Ø£ÙŠ Ø¬Ù…Ù„Ø© ÙŠÙ…ÙƒÙ† Ù„ØµØ­ÙÙŠ Ø±ÙŠØ§Ø¶ÙŠ Ø£Ù† ÙŠÙƒØªØ¨Ù‡Ø§ Ø¨Ø¯ÙˆÙ† Ø®Ø¬Ù„
  âœ— Ø£ÙƒØ«Ø± Ù…Ù† Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© (Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ø­Ø§Ø¯ ÙÙ‚Ø·)
  âœ— Ù‡Ø§Ø´ØªØ§Ù‚Ø§Øª (#) Ø£Ùˆ Ø¥Ø´Ø§Ø±Ø§Øª (@)

â•â•â• Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ â•â•â•
  Lag Â· Timeout Â· Bug Â· 404 Â· Patch Â· Deployment failed Â· Memory leak Â·
  Server crash Â· Firewall breach Â· Cache clear Â· Kernel panic Â· Null pointer Â·
  CPU overload Â· Rollback Â· Hotfix Â· Debug mode Â· Ping spike Â·
  Ø³ÙŠØ±ÙØ± Â· Ù„Ø§Ù‚ Â· Ø¨Ø§Ù‚ Â· ØªØ§ÙŠÙ… Ø£ÙˆØª Â· ÙƒØ§Ø´

â•â•â• ØªØ­Ù‚Ù‚ Ø°Ø§ØªÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ (Ø£Ø¹Ø¯ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¥Ø°Ø§ ÙØ´Ù„ Ø£ÙŠ Ù…Ù†Ù‡Ø§) â•â•â•
  1. Ø§Ù„Ù„ØºØ© ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ØªØºØ±ÙŠØ¯Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
  2. PART 1 (Ø§Ù„Ø·Ø¹Ù†Ø©) Ù…ÙˆØ¬ÙˆØ¯Ø©
  3. PART 2 (Ø§Ù„Ù…ØµØ·Ù„Ø­ Ø§Ù„ØªÙ‚Ù†ÙŠ) Ù…ÙˆØ¬ÙˆØ¯Ø©
  4. PART 3 (Ø§Ù„Ù‚ÙÙ„Ø©) Ø­Ø§Ø¯Ø© ÙˆÙ…ÙØ§Ø¬Ø¦Ø©
  5. Ù„Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©: â‰¥1 banter token Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡
  6. ØµÙØ± ØµÙŠØ§ØºØ© ØµØ­ÙÙŠØ© Ø£Ùˆ ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø§ÙŠØ¯
  7. Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¢Ù…Ù† ÙˆÙ†Ø¸ÙŠÙ
  8. Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ø­Ø§Ø¯ â‰¤240 Ø­Ø±Ù
"""

# Style seeds drive creative variety
_STYLE_SEEDS_AR: list[str] = [
    # â”€â”€ original seeds â”€â”€
    "Ø·Ù‚Ø·Ù‚Ø© Ø®ÙÙŠÙØ© Ù…Ø¹ Ù‚ÙÙ„Ø© Ø³Ø¹ÙˆØ¯ÙŠØ©",
    "Ù…Ù‚Ù„Ø¨ ØªÙ‚Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙØ§Ø¹",
    "Ø³Ø®Ø±ÙŠØ© ÙƒØ±ÙˆÙŠØ© Ø³Ø±ÙŠØ¹Ø©",
    "Ø°Ø¨Ø© Ù‚ØµÙŠØ±Ø© ÙˆØªÙ…ÙˆÙ†",
    "Ù†ÙØ³ Ù…Ø´Ø¬Ø¹ ÙØ§ØµÙ„ Ø¨Ø¹Ø¯ Ù…Ø¨Ø§Ø±Ø§Ø©",
    # â”€â”€ guided improvisation: Saudi daily-life metaphors â”€â”€
    "ØªØ´Ø¨ÙŠÙ‡ Ø§Ù„Ø¯ÙØ§Ø¹ Ø¨Ø´Ø¨ÙƒØ© Ø§ØªØµØ§Ù„ ÙˆØ§Ù‚ÙØ© ÙÙŠ Ø­ÙÙ„",
    "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù‡Ø¬ÙˆÙ… Ø¨Ø·Ø§Ø¨ÙˆØ± Ø¯ÙˆØ§Ø¦Ø± Ø­ÙƒÙˆÙ…ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ø¸Ù‡Ø±",
    "Ø°Ø¨Ø© Ø¨Ø±ÙˆØ­ Ø¬Ù„Ø³Ø© Ù‚Ù‡ÙˆØ© Ø³Ø¹ÙˆØ¯ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¨Ø§Ø±Ø§Ø©",
    "ØªØ´Ø¨ÙŠÙ‡ Ø§Ù„ØªÙƒØªÙŠÙƒ Ø¨Ø·Ù„Ø¨ÙŠØ© Ø£ÙˆØ¨Ø± Ù…Ø§ ÙˆØµÙ„Øª ÙˆÙ…Ø§ Ø£Ù„ØºØª",
    "Ø³Ø®Ø±ÙŠØ© ØªØ±Ø¨Ø· Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¨Ù…Ø²Ø§Ø¬ Ø§Ù„ÙƒØ§Ø¨ØªÙ† ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù†ÙŠ",
    "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¯Ø§ÙØ¹ Ø¨Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø¬Ù…Ø§Ø±Ùƒ Ù„Ù…Ø§ ØªÙ„Ø§Ù‚ Ø§ØªØµØ§Ù„ Ø¶Ø¹ÙŠÙ",
]
_STYLE_SEEDS_EN: list[str] = [
    # â”€â”€ original seeds â”€â”€
    "short savage banter",
    "cold tech roast",
    "dry sarcastic jab",
    "football meme energy",
    "one-liner troll",
    # â”€â”€ guided improvisation â”€â”€
    "unexpected Saudi-life comparison with tech twist",
    "creative metaphor linking the squad to a crashing app",
    "absurdist football debug humor",
]


def _build_user_prompt(tweet_text: str, lang_hint: str) -> tuple[str, str]:
    """Return (seed, user_prompt) for the given tweet and language."""
    seed = random.choice(_STYLE_SEEDS_AR if lang_hint == "ar" else _STYLE_SEEDS_EN)
    if lang_hint == "en":
        structure_line = (
            "Must follow the 3-part structure: "
            "(1) jab at the club/situation  (2) tech metaphor  (3) sharp meme-like punchline. "
            "For English: embed â‰¥1 club banter token "
            "(e.g. '404 trophies', 'nostalgia build', 'beta champions', 'chaos patch', "
            "'plot armor', 'financial plugin', 'debt mode', 'no-trophy mode')."
        )
    else:
        structure_line = (
            "Must follow the 3-part structure: "
            "(1) jab at the club/situation  (2) tech metaphor  (3) sharp meme-like punchline."
        )
    user_prompt = (
        f"Style seed: {seed}\n\n"
        f"Target tweet:\n{tweet_text}\n\n"
        f"Write ONE reply tweet now. {structure_line}"
    )
    return seed, user_prompt


def _quality_check_candidate(reply: str, lang_hint: str, attempt: int,
                              recent_metaphors: list[str], engine_tag: str) -> str | None:
    """Run quality gate + anti-repeat. Returns tech metaphor on pass, None on fail."""
    if not quality_ok(reply, lang_hint):
        if looks_generic(reply):
            block_reason = "generic_match"
        else:
            _has_tech = has_tech_metaphor(reply)
            _has_jab  = has_club_jab(reply)
            _has_sar  = has_sarcasm_marker(reply)
            _score    = sum([_has_tech, _has_jab, _has_sar])
            block_reason = "weak_sarcasm" if (_score < 2 and not _has_sar) else "missing_signals"
        log.info(f"[{engine_tag}] Identity gate: attempt {attempt + 1}/3 BLOCK={block_reason} â†’ retrying")
        return None

    metaphor = _extract_tech_metaphor(reply)
    if metaphor and metaphor in recent_metaphors:
        log.info(f"[{engine_tag}] Identity gate: attempt {attempt + 1}/3 BLOCK=repeated_metaphor({metaphor}) â†’ retrying")
        return None

    if attempt > 0:
        log.info(f"[{engine_tag}] Identity gate: passed on attempt {attempt + 1}")
    return metaphor or ""   # empty string = no metaphor found (still a pass)


GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.0-flash")
_GEMINI_FALLBACKS = ["gemini-1.5-flash-latest", "gemini-2.0-flash", "gemini-1.5-pro"]
_active_gemini_model: str = GEMINI_MODEL


def _generate_gemini(tweet_text: str, lang_hint: str = "en",
                     state: dict | None = None) -> str:
    """Generate reply via Gemini (model: _active_gemini_model).

    Returns FALLBACK_REPLY if all API calls raise exceptions (cycle never stops).
    Returns '' if LLM responded but quality gate kept rejecting (caller skips tweet).
    """
    global _gemini_client, _active_gemini_model
    if _gemini_client is None:
        key = (os.getenv("GEMINI_API_KEY") or "").strip()
        if not key:
            raise RuntimeError("GEN_ENGINE=gemini requires GEMINI_API_KEY")
        _gemini_client = genai.Client(api_key=key)
        log.info("[Gemini] client ready â€“ active model: %s", _active_gemini_model)

    _, user_prompt = _build_user_prompt(tweet_text, lang_hint)
    recent_metaphors: list[str] = (state or {}).get("recent_metaphors", [])
    api_error_count = 0

    for attempt in range(3):
        try:
            resp = _gemini_client.models.generate_content(
                model=_active_gemini_model,
                contents=user_prompt,
                config=genai_types.GenerateContentConfig(
                    system_instruction=GEMINI_CONSTITUTION,
                    max_output_tokens=120,
                    temperature=min(0.80 + attempt * 0.05, 1.0),
                ),
            )
            text  = (resp.text or "").strip()
            reply = " ".join(text.splitlines()).strip()[:240]

            metaphor = _quality_check_candidate(reply, lang_hint, attempt, recent_metaphors, "Gemini")
            if metaphor is None:
                continue

            if state is not None and metaphor:
                state.setdefault("recent_metaphors", []).append(metaphor)
                state["recent_metaphors"] = state["recent_metaphors"][-20:]
            return reply

        except Exception as e:
            api_error_count += 1
            err_str = str(e)
            log.error("[Gemini] LLM fail (attempt %d): %s", attempt + 1, e)
            # 404 model not found â€“ list available and switch to first working fallback
            if "404" in err_str and (
                "not found" in err_str.lower() or "not supported" in err_str.lower()
            ):
                try:
                    all_models = list(_gemini_client.models.list())
                    gen_models = [
                        m.name for m in all_models
                        if "generateContent" in (
                            getattr(m, "supported_actions", None)
                            or getattr(m, "supported_generation_methods", None)
                            or []
                        )
                    ]
                    log.warning(
                        "[Gemini] 404 model=%s not found. generateContent models (first 5): %s",
                        _active_gemini_model, gen_models[:5],
                    )
                except Exception:
                    gen_models = []
                fallback_pool = gen_models if gen_models else _GEMINI_FALLBACKS
                for fb in fallback_pool:
                    if fb != _active_gemini_model:
                        log.warning("[Gemini] 404 â†’ switching active model to %s", fb)
                        _active_gemini_model = fb
                        break

    if api_error_count == 3:
        log.warning("[Gemini] All 3 API calls failed â€“ using text fallback, cycle continues")
        return _pick_fallback()

    log.warning("[Gemini] All 3 attempts failed quality gate â€“ tweet will be skipped")
    return ""


def generate_reply(tweet_text: str, lang_hint: str = "en",
                   state: dict | None = None) -> str:
    """Generate a reply via Gemini. Returns '' on failure â€“ caller skips tweet."""
    return _generate_gemini(tweet_text, lang_hint, state)


def detect_arabic(text: str) -> bool:
    return bool(re.search(r"[\u0600-\u06FF]", text))


# â”€â”€ X / Twitter client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

x = tweepy.Client(
    consumer_key=X_API_KEY,
    consumer_secret=X_API_SECRET,
    access_token=X_ACCESS_TOKEN,
    access_token_secret=X_ACCESS_SECRET,
    wait_on_rate_limit=True,
)


def _block_reason(text: str, lang_hint: str) -> str:
    """Return a specific BLOCK reason code for logging when quality_ok() fails."""
    if looks_generic(text):
        return "generic_match"
    _has_tech = has_tech_metaphor(text)
    _has_jab  = has_club_jab(text)
    _has_sar  = has_sarcasm_marker(text)
    if sum([_has_tech, _has_jab, _has_sar]) < 2 and not _has_sar:
        return "weak_sarcasm"
    return "missing_signals"


def _snipe_engage(tweet_id: int, my_id: int,
                  liked_set: set[str], state: dict) -> None:
    """Like *tweet_id* (if not already liked) then wait 2-4 s.

    This satisfies X's "engage before reply" conversation-control rule.
    Errors are swallowed so a like failure never blocks the reply attempt.
    """
    tid = str(tweet_id)
    if tid in liked_set:
        return
    try:
        if not DRY_RUN:
            x.like(my_id, tweet_id, user_auth=True)
        log.info("Snipe engage: liked tweet %s", tid)
    except Exception as like_err:
        log.warning("Snipe engage: like failed (%s) â€“ proceeding anyway", like_err)
    liked_set.add(tid)
    state["liked_tweet_ids"].append(tid)
    time.sleep(random.uniform(2, 4))


def post_reply(state: dict, in_reply_to_tweet_id: int, text: str,
               lang_hint: str = "en") -> None:
    # Final quality gate â€“ last line of defence before create_tweet
    if not quality_ok(text, lang_hint):
        reason = _block_reason(text, lang_hint)
        log.warning(
            "[BLOCKED] reply suppressed BLOCK=%s | %r", reason, text[:80]
        )
        return
    if DRY_RUN:
        log.info(f"[DRY_RUN] Would reply to {in_reply_to_tweet_id}: {text}")
        record_action(state)
        return
    try:
        x.create_tweet(text=text, in_reply_to_tweet_id=in_reply_to_tweet_id, user_auth=True)
        log.info("posted=reply tweet_id=%s", in_reply_to_tweet_id)
        record_action(state)
    except tweepy.Forbidden as e:
        err_str = str(e).lower()
        resp_body = ""
        try:
            resp_body = e.response.text.lower()
        except AttributeError:
            pass
        api_msgs = " ".join(str(m) for m in getattr(e, "api_messages", [])).lower()
        full_err = err_str + " " + resp_body + " " + api_msgs
        if ("not allowed" in full_err or "conversation" in full_err
                or "mentioned" in full_err or "349" in full_err):
            log.warning("fallback=quote_403 tweet_id=%s", in_reply_to_tweet_id)
            x.create_tweet(text=text, quote_tweet_id=in_reply_to_tweet_id, user_auth=True)
            log.info("posted=quote tweet_id=%s", in_reply_to_tweet_id)
            record_action(state)
        else:
            raise


def post_tweet(state: dict, text: str, lang_hint: str = "ar") -> None:
    # Final quality gate â€“ last line of defence before create_tweet
    if not quality_ok(text, lang_hint):
        reason = _block_reason(text, lang_hint)
        log.warning(
            "[BLOCKED] tweet suppressed BLOCK=%s | %r", reason, text[:80]
        )
        return
    if DRY_RUN:
        log.info(f"[DRY_RUN] Would tweet: {text}")
        record_action(state)
        return
    x.create_tweet(text=text, user_auth=True)
    record_action(state)


# â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def resolve_user_ids(usernames: dict[str, dict]) -> dict[str, dict]:
    resolved: dict[str, dict] = {}
    for uname, meta in usernames.items():
        try:
            u = x.get_user(username=uname, user_auth=True)
            if u and u.data:
                resolved[uname] = {**meta, "id": str(u.data.id)}
            else:
                log.warning(f"Could not resolve @{uname}")
        except Exception as e:
            log.warning(f"resolve @{uname}: {e}")
    return resolved


def is_derby(tweet_text: str) -> bool:
    t = tweet_text.lower()
    return any(a.lower() in t and b.lower() in t for a, b in RIVAL_PAIRS)


# â”€â”€ Recovery mode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def run_recovery_mode(state: dict) -> None:
    """Post one safe banter tweet in low-frequency mode. Replies disabled."""
    ok, reason = governor_allows(state, derby=False)
    if not ok:
        log.info(f"Recovery: skip â€“ {reason}")
        return

    base = "Ø§Ù„Ø¯ÙˆØ±ÙŠ Ù‡Ø°Ø§ ÙƒØ£Ù†Ù‡ Ø³ÙŠØ±ÙØ± ØªØ­Øª Ø¶ØºØ·â€¦ Ø§Ù„Ù„ÙŠ Ø¯ÙØ§Ø¹Ù‡ ÙŠÙ‡Ù†Ù‚ Ù„Ø§ ÙŠÙ„ÙˆÙ… Ø¥Ù„Ø§ Ù†ÙØ³Ù‡."
    reply = ""
    for attempt in range(3):
        cand = generate_reply(base, lang_hint="ar", state=state)
        if quality_ok(cand, "ar"):
            reply = cand
            break
        log.info(f"Recovery: quality_ok fail attempt {attempt + 1} â†’ retrying")

    if not reply:
        log.info("Recovery: no quality draft â€“ skipping")
        return

    log.info(f"Recovery posting: {reply}")
    post_tweet(state, reply, lang_hint="ar")

    silence_h = random.randint(*RECOVERY_SILENCE_H)
    log.info(f"Recovery: silence window {silence_h}h")
    time.sleep(silence_h * 3600)


# â”€â”€ Main loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def monitor_mentions_and_snipes() -> None:
    state = load_state()
    replied_set: set[str] = set(state.get("replied_tweet_ids", []))
    liked_set:   set[str] = set(state.get("liked_tweet_ids",   []))

    me = x.get_me(user_auth=True)
    if not me or not me.data:
        raise RuntimeError("Failed to get authenticated user â€“ check X API keys")
    my_id = me.data.id

    log.info("=" * 60)
    log.info(f"BugKSA online  my_id={my_id}  DRY_RUN={DRY_RUN}  RECOVERY_MODE={RECOVERY_MODE}  GEN_ENGINE={GEN_ENGINE}  CLUB_SNIPING={CLUB_SNIPING}")
    log.info(
        f"Governor: gapâ‰¥{MIN_GAP_SECONDS // 60}min | burstâ‰¤{DERBY_BURST_MAX_30MIN}/30min | "
        f"{MAX_PER_HOUR}/hr | {MAX_PER_DAY}/day | humanize_skip={int(HUMANIZE_SKIP_RATE * 100)}%"
    )
    log.info("=" * 60)

    targets = resolve_user_ids(TARGET_USERNAMES)
    log.info(f"Resolved {len(targets)}/{len(TARGET_USERNAMES)} targets.")

    cycle = 0
    while True:
        cycle += 1
        log.info(f"â”€â”€ Cycle {cycle} " + "â”€" * 40)
        did_action = False

        try:
            if RECOVERY_MODE:
                run_recovery_mode(state)
                continue

            # â”€â”€ 1. Mentions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            mentions = x.get_users_mentions(
                id=my_id,
                since_id=state.get("last_mention_id"),
                max_results=10,
                user_auth=True,
            )
            if mentions and mentions.data:
                if mentions.meta and mentions.meta.get("newest_id"):
                    state["last_mention_id"] = mentions.meta["newest_id"]

                for tw in mentions.data[:1]:  # at most 1 per cycle
                    tid = str(tw.id)
                    if tid in replied_set:
                        log.info(f"Mention {tid}: already replied â€“ skip")
                        continue

                    # Humanize: intentionally skip 40 % of opportunities
                    if random.random() < HUMANIZE_SKIP_RATE:
                        log.info(f"Mention {tid}: humanized skip â€“ will retry next cycle")
                        continue

                    derby = is_derby(tw.text)
                    ok, reason = governor_allows(state, derby=derby)
                    if not ok:
                        log.info(f"Mention {tid}: governor â€“ {reason}")
                        break

                    lang_hint = "ar" if detect_arabic(tw.text) else "en"
                    reply = ""
                    for attempt in range(3):
                        cand = generate_reply(tw.text, lang_hint=lang_hint, state=state)
                        if quality_ok(cand, lang_hint):
                            reply = cand
                            break
                        log.info(f"Mention {tid} quality_ok fail attempt {attempt + 1} â†’ retrying")

                    if not reply:
                        log.info(f"Mention {tid}: no quality reply after 3 attempts â€“ skip")
                        replied_set.add(tid)
                        state["replied_tweet_ids"].append(tid)
                        save_state(state)
                        continue

                    log.info(f"Mention {tid}: replying â†’ {reply}")
                    try:
                        post_reply(state, tw.id, reply, lang_hint)
                    except Exception as mention_err:
                        m_str = str(mention_err).lower()
                        m_body = ""
                        try:
                            m_body = mention_err.response.text.lower()
                        except AttributeError:
                            pass
                        m_msgs = " ".join(
                            str(m) for m in getattr(mention_err, "api_messages", [])
                        ).lower()
                        full_m = m_str + " " + m_body + " " + m_msgs
                        if "duplicate" in full_m or "187" in full_m:
                            log.warning("Mention %s: duplicate content â€“ skip", tid)
                            replied_set.add(tid)
                            state["replied_tweet_ids"].append(tid)
                            save_state(state)
                            continue
                        raise
                    replied_set.add(tid)
                    state["replied_tweet_ids"].append(tid)
                    if derby:
                        state["derby_burst_log"].append(now_ts())
                    save_state(state)
                    did_action = True

            # â”€â”€ 2. Club radar (sniping) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Disabled by default: CLUB_SNIPING=false (free-tier safe).
            # GET /2/users/:id/tweets requires Basic/Pro X API plan.
            # Set env var CLUB_SNIPING=true only after confirming your plan allows it.
            if not CLUB_SNIPING:
                log.debug("Club sniping disabled (CLUB_SNIPING=false) â€“ skipping timeline polling")
            else:
                for uname, meta in targets.items():
                    uid = meta.get("id")
                    if not uid:
                        continue

                    last_seen = state["last_seen_by_user"].get(uid)
                    tweets = x.get_users_tweets(
                        id=uid,
                        since_id=last_seen,
                        max_results=5,
                        user_auth=True,
                        exclude=["replies", "retweets"],
                        tweet_fields=[
                            "reply_settings",
                            "referenced_tweets",
                            "lang",
                            "author_id",
                            "conversation_id",
                        ],
                    )
                    if not tweets or not tweets.data:
                        continue

                    if tweets.meta and tweets.meta.get("newest_id"):
                        state["last_seen_by_user"][uid] = tweets.meta["newest_id"]

                    for tw in tweets.data:
                        tid = str(tw.id)
                        if tid in replied_set:
                            continue
                        if tw.text.strip().startswith("RT"):
                            continue
                        if tw.text.count("http") >= 2:
                            replied_set.add(tid)
                            state["replied_tweet_ids"].append(tid)
                            save_state(state)
                            continue
                        rs = getattr(tw, "reply_settings", "everyone")
                        if rs != "everyone":
                            log.info("Snipe @%s %s: skip=reply_settings val=%s", uname, tid, rs)
                            continue

                        ref_types = {
                            r.get("type") if isinstance(r, dict) else getattr(r, "type", "")
                            for r in (getattr(tw, "referenced_tweets", None) or [])
                        }
                        if ref_types & {"replied_to", "retweeted"}:
                            log.info("Snipe @%s %s: skip=non_original ref=%s", uname, tid, ref_types)
                            continue

                        # Humanize: clubs skip 40 %, personality accounts skip 70 %
                        skip_rate = PERSONALITY_SKIP_RATE if meta.get("origin") == "personality" else HUMANIZE_SKIP_RATE
                        if random.random() < skip_rate:
                            log.info("Snipe @%s %s: skip=humanized", uname, tid)
                            continue

                        derby = is_derby(tw.text)
                        ok, reason = governor_allows(state, derby=derby)
                        if not ok:
                            log.info(f"Snipe @{uname}: governor â€“ {reason}")
                            break

                        lang_hint = "ar" if detect_arabic(tw.text) else "en"
                        reply = ""
                        for attempt in range(3):
                            cand = generate_reply(tw.text, lang_hint=lang_hint, state=state)
                            if quality_ok(cand, lang_hint):
                                reply = cand
                                break
                            log.info(f"Snipe @{uname} quality_ok fail attempt {attempt + 1} â†’ retrying")

                        if not reply:
                            log.info(f"Snipe @{uname}: no quality reply â€“ skip")
                            replied_set.add(tid)
                            state["replied_tweet_ids"].append(tid)
                            save_state(state)
                            continue

                        # Engage-before-reply: like the tweet first so X allows our reply
                        _snipe_engage(tw.id, my_id, liked_set, state)

                        log.info(f"Snipe @{uname}: replying â†’ {reply}")
                        post_reply(state, tw.id, reply, lang_hint)
                        replied_set.add(tid)
                        state["replied_tweet_ids"].append(tid)
                        if derby:
                            state["derby_burst_log"].append(now_ts())
                        save_state(state)
                        did_action = True

        except Exception as e:
            # 402 = credits exhausted â€“ sleep 1 h, don't hammer the API
            if "402" in str(e) or "payment required" in str(e).lower():
                log.critical(
                    "CREDITS EXHAUSTED (402) â€“ top up at developer.x.com "
                    "Sleeping 1 h before retry."
                )
                time.sleep(3600)
            else:
                log.error(f"Cycle error: {e}")
                time.sleep(60)
            continue

        if not did_action:
            log.info("Cycle complete: no action taken.")

        # Cycle sleep: 5-10 min
        sleep_s = random.randint(300, 600)
        log.info(f"Sleeping {sleep_s}s ({sleep_s // 60}m {sleep_s % 60}s) â€¦")
        time.sleep(sleep_s)


if __name__ == "__main__":
    monitor_mentions_and_snipes()
